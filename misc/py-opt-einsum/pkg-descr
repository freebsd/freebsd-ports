Optimized einsum can significantly reduce the overall execution time of
einsum-like expressions (e.g., np.einsum, dask.array.einsum, pytorch.einsum,
tensorflow.einsum, ) by optimizing the expression's contraction order and
dispatching many operations to canonical BLAS, cuBLAS, or other specialized
routines.

Optimized einsum is agnostic to the backend and can handle NumPy, Dask, PyTorch,
Tensorflow, CuPy, Sparse, Theano, JAX, and Autograd arrays as well as
potentially any library which conforms to a standard API.
